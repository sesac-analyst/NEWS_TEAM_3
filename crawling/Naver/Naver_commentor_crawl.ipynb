{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf945231-4932-46c3-8d66-5bec47e2c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#댓글 유저를 특정해서 댓글을 단 기사 crawling\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import uuid  # To generate unique identifiers\n",
    "\n",
    "# 시간으로 크롤링 시간 제한\n",
    "time_limit = 1200  # 20 minutes, change to 3600 for 1 hour\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 크롬 드라이버 작동\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://n.news.naver.com/mnews/article/comment/243/0000058980#user_comment_824138786735652991_news243')\n",
    "time.sleep(3)\n",
    "\n",
    "# date, time과 unique identifier를 구분하여 저장\n",
    "def save_info_to_file(comment, date, source, link_href):\n",
    "    # Use the date element to create a file name\n",
    "    date_for_filename = date.split()[0].replace('.', '-')  # Format date for file name\n",
    "    time_for_filename = datetime.now().strftime(\"%H_%M_%S\")  # Get current time for unique filename\n",
    "    unique_id = uuid.uuid4().hex[:6]  # Generate a unique ID\n",
    "    file_name = f\"C:\\\\Users\\\\rapha\\\\PJ\\\\PJ_04\\\\commentor\\\\{date_for_filename}_{time_for_filename}_{unique_id}_comment_data.txt\"\n",
    "\n",
    "    \n",
    "    # text 파일로 저장\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Comment: {comment}\\n\")\n",
    "        f.write(f\"Date: {date}\\n\")\n",
    "        f.write(f\"Source: {source}\\n\")\n",
    "        f.write(f\"Link: {link_href}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")  # Separator\n",
    "    #print(f\"Info saved to file: {file_name}\")\n",
    "\n",
    "# 시간제한까지 반복실행\n",
    "while True:\n",
    "    # Check if the time limit has been reached\n",
    "    if time.time() - start_time > time_limit:\n",
    "        print(\"Time limit reached. Stopping the script.\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # \"더 보기\" 버튼 누르기\n",
    "        more_button = driver.find_element(By.CSS_SELECTOR, '#wa_allcomments > div.u_cbox_paginate.is_more_button > a > span > span > span.u_cbox_page_more')\n",
    "        more_button.click()\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(\"No more comments to load or error occurred:\", e)\n",
    "        break\n",
    "\n",
    "    # Parsing\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 댓글 부분 선택택\n",
    "    comment_elements = soup.select('#cbox_module_wai_u_cbox_content_wrap_tabpanel > ul > li.u_cbox_comment')\n",
    "\n",
    "    for comment_element in comment_elements:\n",
    "        # 링크, 삭제된 본문, 날짜 정보 추출\n",
    "        link_element = comment_element.select_one('div.u_cbox_comment_box.u_cbox_type_profile > div > div.u_cbox_text_wrap > span.u_cbox_contents > a')\n",
    "        deleted_text_element = comment_element.select_one('div.u_cbox_orgsourcedel > span.u_cbox_orgsourcedel_txt')\n",
    "        orgsource_element = comment_element.select_one('div.u_cbox_comment_box.u_cbox_type_profile > div > div.u_cbox_orgsource > a > div.u_cbox_orgsource_content > strong')\n",
    "        link_element_2 = comment_element.select_one('div.u_cbox_comment_box.u_cbox_type_profile > div > div.u_cbox_orgsource > a')\n",
    "        date_element = comment_element.select_one('div.u_cbox_comment_box.u_cbox_type_profile > div > div.u_cbox_info_base > span')\n",
    "\n",
    "        # 데이터 저장 목록\n",
    "        comment_text = \"N/A\"\n",
    "        date_text = \"N/A\"\n",
    "        source_text = \"N/A\"\n",
    "        link_href = \"N/A\"\n",
    "\n",
    "        # 데이터 수집\n",
    "        if link_element:\n",
    "            comment_text = link_element.get_text()\n",
    "            print(\"Comment:\", comment_text)\n",
    "\n",
    "        if date_element:\n",
    "            date_text = date_element.get_text()\n",
    "            print(\"Date:\", date_text)\n",
    "\n",
    "        if orgsource_element:\n",
    "            source_text = orgsource_element.get_text()\n",
    "            print(\"Source:\", source_text)\n",
    "\n",
    "        if deleted_text_element and deleted_text_element.get_text() == '언론사에 의해 삭제된 기사입니다.':\n",
    "            source_text = '언론사에 의해 삭제된 기사입니다.'\n",
    "            print(\"Deleted article detected.\")\n",
    "\n",
    "        if link_element_2:\n",
    "            link_href = link_element_2.get('href')\n",
    "            print(\"Link href:\", link_href)\n",
    "\n",
    "        # 수집된 데이터 저장\n",
    "        save_info_to_file(comment_text, date_text, source_text, link_href)\n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51e5849-a42c-4edb-bdf4-e56f679addab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated data saved to concatenated_comments.txt\n"
     ]
    }
   ],
   "source": [
    "#text 파일 합치기(na 제외)\n",
    "import os\n",
    "\n",
    "directory = r\"C:\\Users\\rapha\\PJ\\PJ_04\\commentor\"\n",
    "\n",
    "output_file = \"concatenated_comments.txt\"\n",
    "\n",
    "# 'N/A'값이 있는지 확인\n",
    "def contains_na(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        return 'N/A' in content\n",
    "\n",
    "# 저장 파일 \n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # 'N/A'값이 있는지 확인\n",
    "        if not contains_na(file_path):\n",
    "            # If not, read the file and write its content to the output file\n",
    "            with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                outfile.write(infile.read())\n",
    "                outfile.write(\"\\n\" + \"-\" * 50 + \"\\n\")  # Separator between files\n",
    "\n",
    "print(f\"Concatenated data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875fcd7b-a9e1-415f-8f13-72a29aebfe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to comments_data.csv\n"
     ]
    }
   ],
   "source": [
    "# csv로 전환\n",
    "import csv\n",
    "\n",
    "input_file = r\"C:\\Users\\rapha\\PJ\\PJ_04\\concatenated_comments.txt\"\n",
    "\n",
    "output_csv = \"comments_data.csv\"\n",
    "\n",
    "data = []\n",
    "\n",
    "# 텍스트파일 불러오기\n",
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    lines = infile.readlines()\n",
    "    \n",
    "    comment = date = source = link = None\n",
    "    \n",
    "    # 데이터 추출\n",
    "    for line in lines:\n",
    "        if line.startswith(\"Comment:\"):\n",
    "            comment = line.split(\"Comment:\")[1].strip()\n",
    "        elif line.startswith(\"Date:\"):\n",
    "            date = line.split(\"Date:\")[1].strip()\n",
    "        elif line.startswith(\"Source:\"):\n",
    "            source = line.split(\"Source:\")[1].strip()\n",
    "        elif line.startswith(\"Link:\"):\n",
    "            link = line.split(\"Link:\")[1].strip()\n",
    "        elif line.startswith(\"-\" * 50):\n",
    "            # 추출된 데이터 리스트에 추가\n",
    "            if comment and date and source and link:\n",
    "                data.append([comment, date, source, link])\n",
    "            # 다음 댓글을 위해 초기화\n",
    "            comment = date = source = link = None\n",
    "\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"Comment\", \"Date\", \"Source\", \"Link\"])\n",
    "    csvwriter.writerows(data)\n",
    "\n",
    "print(f\"Data successfully saved to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
